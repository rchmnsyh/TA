{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4798"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"new_reviews.csv\", names=[\"Review\"])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing - Drop NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4159"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.74 seconds)\n",
      "Writing emoji data to C:\\Users\\rachm\\.demoji\\codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "\n",
    "# def deEmojify(text):\n",
    "#     regrex_pattern = re.compile(pattern = \"[\"\n",
    "#         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            \"]+\", flags = re.UNICODE)\n",
    "#     return regrex_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Tiap makan kesini ngga pernah cuma 1 atau 2 porsi, pasti nambah terus, karena emang pas banget rasanya di lidah. Black peppernya yang paling enak disini.  Emang selalu waiting list, cuma sei sapi lamalera absolutely worth to wait! Recommended!\n",
      "\n",
      "Hapus Emoji: Tiap makan kesini ngga pernah cuma 1 atau 2 porsi, pasti nambah terus, karena emang pas banget rasanya di lidah. Black peppernya yang paling enak disini.  Emang selalu waiting list, cuma sei sapi lamalera absolutely worth to wait! Recommended!\n",
      "\n",
      "Tokenize: ['Tiap', 'makan', 'kesini', 'ngga', 'pernah', 'cuma', '1', 'atau', '2', 'porsi,', 'pasti', 'nambah', 'terus,', 'karena', 'emang', 'pas', 'banget', 'rasanya', 'di', 'lidah.', 'Black', 'peppernya', 'yang', 'paling', 'enak', 'disini.', 'Emang', 'selalu', 'waiting', 'list,', 'cuma', 'sei', 'sapi', 'lamalera', 'absolutely', 'worth', 'to', 'wait!', 'Recommended!']\n",
      "\n",
      "Before: Seâ€™i sapi sambel Luâ€™at nya dabest!   Pertama kesini pas jam 8 malam tp udh close order dan cuma bisa take away karna udh terlalu ramai mungkin ya, tapi ga asik ya kalo kali pertama nyobain Seâ€™i tapi dibungkus ðŸ˜‚   Jadi kita mutusin untuk dateng lg besok paginya dan kita pesan ini: âœ¨ Seâ€™i sapi sambel Luâ€™at  âœ¨ Seâ€™i sapi sambel Matah âœ¨ Seâ€™i sapi sambel Ijo âœ¨ Seâ€™i sapi sambel Andaliman âœ¨ Seâ€™i sapi Rica-Rica  Untuk semua daging rasanya sama, hanya sambel nya aja yg ngebedain. Dari semua sambel, aku paling suka sambel Luâ€™at ðŸ¥º rasa sambelnya seru gtu seger dan mungkin karna ada perasan jeruk nipis nya(?) Untuk pelayanannya cukup cepat dan ambiance nya jg oke.  Kalau mau kesini hindari jam makan siang ya, waiting listnya ganahan hehe. Tp kalau km termasuk org yang sabar, km bisa makan Cilor goreng yg dijual percis didepan kedai sambil nunggu antrian. Selamat mencoba! ðŸ˜‰\n",
      "\n",
      "Hapus Emoji: Seâ€™i sapi sambel Luâ€™at nya dabest!   Pertama kesini pas jam 8 malam tp udh close order dan cuma bisa take away karna udh terlalu ramai mungkin ya, tapi ga asik ya kalo kali pertama nyobain Seâ€™i tapi dibungkus    Jadi kita mutusin untuk dateng lg besok paginya dan kita pesan ini:  Seâ€™i sapi sambel Luâ€™at   Seâ€™i sapi sambel Matah  Seâ€™i sapi sambel Ijo  Seâ€™i sapi sambel Andaliman  Seâ€™i sapi Rica-Rica  Untuk semua daging rasanya sama, hanya sambel nya aja yg ngebedain. Dari semua sambel, aku paling suka sambel Luâ€™at  rasa sambelnya seru gtu seger dan mungkin karna ada perasan jeruk nipis nya(?) Untuk pelayanannya cukup cepat dan ambiance nya jg oke.  Kalau mau kesini hindari jam makan siang ya, waiting listnya ganahan hehe. Tp kalau km termasuk org yang sabar, km bisa makan Cilor goreng yg dijual percis didepan kedai sambil nunggu antrian. Selamat mencoba! \n",
      "\n",
      "Tokenize: ['Seâ€™i', 'sapi', 'sambel', 'Luâ€™at', 'nya', 'dabest!', 'Pertama', 'kesini', 'pas', 'jam', '8', 'malam', 'tp', 'udh', 'close', 'order', 'dan', 'cuma', 'bisa', 'take', 'away', 'karna', 'udh', 'terlalu', 'ramai', 'mungkin', 'ya,', 'tapi', 'ga', 'asik', 'ya', 'kalo', 'kali', 'pertama', 'nyobain', 'Seâ€™i', 'tapi', 'dibungkus', 'Jadi', 'kita', 'mutusin', 'untuk', 'dateng', 'lg', 'besok', 'paginya', 'dan', 'kita', 'pesan', 'ini:', 'Seâ€™i', 'sapi', 'sambel', 'Luâ€™at', 'Seâ€™i', 'sapi', 'sambel', 'Matah', 'Seâ€™i', 'sapi', 'sambel', 'Ijo', 'Seâ€™i', 'sapi', 'sambel', 'Andaliman', 'Seâ€™i', 'sapi', 'Rica-Rica', 'Untuk', 'semua', 'daging', 'rasanya', 'sama,', 'hanya', 'sambel', 'nya', 'aja', 'yg', 'ngebedain.', 'Dari', 'semua', 'sambel,', 'aku', 'paling', 'suka', 'sambel', 'Luâ€™at', 'rasa', 'sambelnya', 'seru', 'gtu', 'seger', 'dan', 'mungkin', 'karna', 'ada', 'perasan', 'jeruk', 'nipis', 'nya(?)', 'Untuk', 'pelayanannya', 'cukup', 'cepat', 'dan', 'ambiance', 'nya', 'jg', 'oke.', 'Kalau', 'mau', 'kesini', 'hindari', 'jam', 'makan', 'siang', 'ya,', 'waiting', 'listnya', 'ganahan', 'hehe.', 'Tp', 'kalau', 'km', 'termasuk', 'org', 'yang', 'sabar,', 'km', 'bisa', 'makan', 'Cilor', 'goreng', 'yg', 'dijual', 'percis', 'didepan', 'kedai', 'sambil', 'nunggu', 'antrian.', 'Selamat', 'mencoba!']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in (df[\"Review\"][:2]):\n",
    "    print(\"Before:\", sentence)\n",
    "#     sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "#     print()\n",
    "#     print(\"Hapus simbol:\", sentence)\n",
    "#     deEmo = deEmojify(sentence)\n",
    "#     print(\"Using Regex:\", deEmo)\n",
    "    sentence = demoji.replace(sentence)\n",
    "    print()\n",
    "    print(\"Hapus Emoji:\", sentence)\n",
    "    sentence = sentence.split()\n",
    "    print()\n",
    "    print(\"Tokenize:\", sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 864/864 [00:29<00:00, 29.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_hasil = pd.DataFrame(columns=['Kalimat #', 'Word'])\n",
    "kalimat = 1\n",
    "\n",
    "for sentence in (tqdm(df[\"Review\"], desc=\"Loading...\")):\n",
    "    # print(\"Kalimat\", kalimat)\n",
    "    # sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    sentence = demoji.replace(sentence.lower())\n",
    "    s_token = sentence.split()\n",
    "    s_token = [[kalimat, w] for w in s_token]\n",
    "    # print(s_token)\n",
    "    df_temp = pd.concat([pd.DataFrame([i], columns=['Kalimat #', 'Word']) for i in s_token], ignore_index=True)\n",
    "    df_hasil = df_hasil.append(df_temp, ignore_index=True)\n",
    "    kalimat = kalimat + 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tiap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>makan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>kesini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ngga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>pernah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51275</th>\n",
       "      <td>864</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51276</th>\n",
       "      <td>864</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51277</th>\n",
       "      <td>864</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51278</th>\n",
       "      <td>864</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51279</th>\n",
       "      <td>864</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51280 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Kalimat #    Word\n",
       "0             1    tiap\n",
       "1             1   makan\n",
       "2             1  kesini\n",
       "3             1    ngga\n",
       "4             1  pernah\n",
       "...         ...     ...\n",
       "51275       864    even\n",
       "51276       864    they\n",
       "51277       864    left\n",
       "51278       864     the\n",
       "51279       864    room\n",
       "\n",
       "[51280 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil.to_csv('reviews_tokenized.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 864/864 [00:01<00:00, 609.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "preprocessed = []\n",
    "for sentence in (tqdm(df[\"Review\"], desc=\"Loading...\")):\n",
    "    # print(\"Kalimat\", kalimat)\n",
    "    # sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    sentence = demoji.replace(sentence.lower())\n",
    "    preprocessed.append(sentence)\n",
    "    pass\n",
    "\n",
    "df_sentence = pd.DataFrame(preprocessed, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiap makan kesini ngga pernah cuma 1 atau 2 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seâ€™i sapi sambel luâ€™at nya dabest!   pertama k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan yang sebenarnya simple tapi enak bange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enak bgtttt, sambel enak, daging sho good gata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rasa sei nya blm ada yg ngalahin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>cozy place with poor service. pelayan menginfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>instagramable place menurut gw, hrga makanan &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>foto dan harga di aplikasi kurang jelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>i like the ambience here... and love the food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>may be better if the smokers places in the out...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    tiap makan kesini ngga pernah cuma 1 atau 2 po...\n",
       "1    seâ€™i sapi sambel luâ€™at nya dabest!   pertama k...\n",
       "2    makanan yang sebenarnya simple tapi enak bange...\n",
       "3    enak bgtttt, sambel enak, daging sho good gata...\n",
       "4                     rasa sei nya blm ada yg ngalahin\n",
       "..                                                 ...\n",
       "859  cozy place with poor service. pelayan menginfo...\n",
       "860  instagramable place menurut gw, hrga makanan &...\n",
       "861            foto dan harga di aplikasi kurang jelas\n",
       "862  i like the ambience here... and love the food ...\n",
       "863  may be better if the smokers places in the out...\n",
       "\n",
       "[864 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence.to_csv('reviews_preprocessed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sentence)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiap makan kesini ngga pernah cuma 1 atau 2 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seâ€™i sapi sambel luâ€™at nya dabest!   pertama k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan yang sebenarnya simple tapi enak bange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enak bgtttt, sambel enak, daging sho good gata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rasa sei nya blm ada yg ngalahin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>mau makan sehat tapi enak dan murah? makan ras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>i love thier concept! first, we have to know i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>the best vegan dining i ever eat.. semua makan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>pesen nasi timbel. enak bgt \"daging\"nyaa kenye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>terlalu lama untuk menunggu makanan selesai di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    tiap makan kesini ngga pernah cuma 1 atau 2 po...\n",
       "1    seâ€™i sapi sambel luâ€™at nya dabest!   pertama k...\n",
       "2    makanan yang sebenarnya simple tapi enak bange...\n",
       "3    enak bgtttt, sambel enak, daging sho good gata...\n",
       "4                     rasa sei nya blm ada yg ngalahin\n",
       "..                                                 ...\n",
       "427  mau makan sehat tapi enak dan murah? makan ras...\n",
       "428  i love thier concept! first, we have to know i...\n",
       "429  the best vegan dining i ever eat.. semua makan...\n",
       "430  pesen nasi timbel. enak bgt \"daging\"nyaa kenye...\n",
       "431  terlalu lama untuk menunggu makanan selesai di...\n",
       "\n",
       "[432 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence.iloc[:len(df_sentence)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>the best burger i had in a while. this place w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>burger dari brother jonn &amp; sons menurut aku ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>tidak seenak yang aku bayangkan rekomen dari o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>seneng banget menemukan tempat burger di bandu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>burger terenak di bandung! lagi liburan cravin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>cozy place with poor service. pelayan menginfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>instagramable place menurut gw, hrga makanan &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>foto dan harga di aplikasi kurang jelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>i like the ambience here... and love the food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>may be better if the smokers places in the out...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "432  the best burger i had in a while. this place w...\n",
       "433  burger dari brother jonn & sons menurut aku ja...\n",
       "434  tidak seenak yang aku bayangkan rekomen dari o...\n",
       "435  seneng banget menemukan tempat burger di bandu...\n",
       "436  burger terenak di bandung! lagi liburan cravin...\n",
       "..                                                 ...\n",
       "859  cozy place with poor service. pelayan menginfo...\n",
       "860  instagramable place menurut gw, hrga makanan &...\n",
       "861            foto dan harga di aplikasi kurang jelas\n",
       "862  i like the ambience here... and love the food ...\n",
       "863  may be better if the smokers places in the out...\n",
       "\n",
       "[432 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence.iloc[len(df_sentence)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence.iloc[:len(df_sentence)//2].to_csv('reviews_preprocessed_firsthalf.csv',index=False)\n",
    "df_sentence.iloc[len(df_sentence)//2:].to_csv('reviews_preprocessed_secondhalf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
