{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiap</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>makan</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kesini</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ngga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pernah</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50531</th>\n",
       "      <td>859</td>\n",
       "      <td>portions</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50532</th>\n",
       "      <td>859</td>\n",
       "      <td>way</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50533</th>\n",
       "      <td>859</td>\n",
       "      <td>too</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50534</th>\n",
       "      <td>859</td>\n",
       "      <td>small</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50535</th>\n",
       "      <td>859</td>\n",
       "      <td>p</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50536 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kalimat #      Word     Tag\n",
       "0              0      tiap       O\n",
       "1              0     makan       O\n",
       "2              0    kesini       O\n",
       "3              0      ngga       O\n",
       "4              0    pernah       O\n",
       "...          ...       ...     ...\n",
       "50531        859  portions  I-FOOD\n",
       "50532        859       way  I-FOOD\n",
       "50533        859       too  I-FOOD\n",
       "50534        859     small  I-FOOD\n",
       "50535        859         p       O\n",
       "\n",
       "[50536 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/dataset_fix.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-FOOD': 1,\n",
       " 'I-FOOD': 2,\n",
       " 'B-MISCELLANEOUS': 3,\n",
       " 'I-MISCELLANEOUS': 4,\n",
       " 'B-SERVICE': 5,\n",
       " 'I-SERVICE': 6,\n",
       " 'B-AMBIENCE': 7,\n",
       " 'I-AMBIENCE': 8,\n",
       " 'B-PRICE': 9,\n",
       " 'I-PRICE': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic={}\n",
    "for i, tag in enumerate(df.Tag.unique()):\n",
    "    dic[tag] = i\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "50531    2\n",
       "50532    2\n",
       "50533    2\n",
       "50534    2\n",
       "50535    0\n",
       "Name: Tag, Length: 50536, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"Tag\"].apply(lambda x:dic[x])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kalimat = []\n",
    "for i in range(df[\"Kalimat #\"].min(),df[\"Kalimat #\"].max()+1):\n",
    "    list_kata = [\"<S>\"]\n",
    "    for kata in df[df[\"Kalimat #\"] == i][\"Word\"]:\n",
    "        list_kata.append(str(kata))\n",
    "    list_kata.append(\"</S>\")\n",
    "    list_kalimat.append(list_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S>',\n",
       " 'tiap',\n",
       " 'makan',\n",
       " 'kesini',\n",
       " 'ngga',\n",
       " 'pernah',\n",
       " 'cuma',\n",
       " '1',\n",
       " 'atau',\n",
       " '2',\n",
       " 'porsi',\n",
       " 'pasti',\n",
       " 'nambah',\n",
       " 'terus',\n",
       " 'karena',\n",
       " 'emang',\n",
       " 'pas',\n",
       " 'banget',\n",
       " 'rasanya',\n",
       " 'di',\n",
       " 'lidah',\n",
       " 'black',\n",
       " 'peppernya',\n",
       " 'yang',\n",
       " 'paling',\n",
       " 'enak',\n",
       " 'disini',\n",
       " 'emang',\n",
       " 'selalu',\n",
       " 'waiting',\n",
       " 'list',\n",
       " 'cuma',\n",
       " 'sei',\n",
       " 'sapi',\n",
       " 'lamalera',\n",
       " 'absolutely',\n",
       " 'worth',\n",
       " 'to',\n",
       " 'wait',\n",
       " 'recommended',\n",
       " '</S>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_kalimat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kalimat_join = []\n",
    "for kalimat in list_kalimat:\n",
    "    list_kalimat_join.append(\" \".join(kalimat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> tiap makan kesini ngga pernah cuma 1 atau 2 porsi pasti nambah terus karena emang pas banget rasanya di lidah black peppernya yang paling enak disini emang selalu waiting list cuma sei sapi lamalera absolutely worth to wait recommended </S>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_kalimat_join[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = []\n",
    "for kalimat in (list_kalimat):\n",
    "    for i in range(len(kalimat)):\n",
    "        if i > 0 and i < len(kalimat)-1:\n",
    "            trigram.append([kalimat[i-1], kalimat[i], kalimat[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idwiki_300 = Word2Vec.load(\"Model/idwiki_word2vec_300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Count before Update = 348902\n",
      "Vocab before Update = 331792\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus Count before Update =\", idwiki_300.corpus_count)\n",
    "print(\"Vocab before Update =\", len(idwiki_300.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415872, 522560)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idwiki_300.build_vocab(list_kalimat, update=True)\n",
    "idwiki_300.train(list_kalimat, total_examples=idwiki_300.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Count after Update = 860\n",
      "Vocab after Update = 331916\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus Count after Update =\", idwiki_300.corpus_count)\n",
    "print(\"Vocab after Update =\", len(idwiki_300.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_dict = {}\n",
    "X = []\n",
    "OOV = 0\n",
    "for i in range(len(trigram)):\n",
    "    wv_trigram = []\n",
    "    for j in range(len(trigram[i])):\n",
    "        try:\n",
    "            wv_trigram = wv_trigram + list(idwiki_300.wv[trigram[i][j]])\n",
    "        except KeyError:\n",
    "            OOV = OOV + 1\n",
    "            if trigram[i][j] not in oov_dict.keys():\n",
    "                oov_dict[trigram[i][j]] = np.random.normal(0,np.sqrt(0.25),300)\n",
    "            wv_trigram = wv_trigram + list(oov_dict[trigram[i][j]])\n",
    "    X.append(wv_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8672"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(x).astype('float32') for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50536, 900)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=1301170066, shuffle=True, stratify=labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(x).astype('float32') for x in X_train])\n",
    "y_train = np.array([np.array(x).astype('float32') for x in y_train])\n",
    "\n",
    "X_test = np.array([np.array(x).astype('float32') for x in X_test])\n",
    "y_test = np.array([np.array(x).astype('float32') for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train: (40428, 900)\n",
      "Shape of label train: (40428,)\n",
      "Shape of X test: (10108, 900)\n",
      "Shape of label test: (10108,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X train:', X_train.shape)\n",
    "print('Shape of label train:', y_train.shape)\n",
    "\n",
    "print('Shape of X test:', X_test.shape)\n",
    "print('Shape of label test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachm\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC()\n",
    "# ovr = OneVsRestClassifier(svclassifier)\n",
    "# random_grid = {'C': [.0001, .001, .01],\n",
    "#                   'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                   'gamma': [.0001, .001, .01, .1, 1, 10, 100],\n",
    "#                   'degree': [1, 2, 3, 4, 5],\n",
    "#                   'probability': [True]\n",
    "#                  }\n",
    "# random_search = RandomizedSearchCV(estimator=svclassifier,\n",
    "#                                    param_distributions=random_grid,\n",
    "#                                    n_iter=50,\n",
    "#                                    scoring='accuracy',\n",
    "#                                    cv=3, \n",
    "#                                    verbose=1, \n",
    "#                                    random_state=8)\n",
    "# random_search.fit(X_train, y_train)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0      0.744     0.081     0.146       395\n",
      "         2.0      0.636     0.296     0.404      1360\n",
      "         3.0      0.333     0.009     0.018       110\n",
      "         4.0      0.500     0.035     0.066       399\n",
      "         5.0      0.750     0.208     0.326        72\n",
      "         6.0      0.769     0.115     0.200       261\n",
      "         7.0      0.533     0.205     0.296        78\n",
      "         8.0      0.613     0.153     0.244       249\n",
      "         9.0      0.720     0.419     0.529        43\n",
      "        10.0      0.714     0.236     0.355       127\n",
      "\n",
      "   micro avg      0.645     0.193     0.297      3094\n",
      "   macro avg      0.631     0.176     0.258      3094\n",
      "weighted avg      0.635     0.193     0.279      3094\n",
      "\n",
      "f1 score: 0.7370399683419074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "print(classification_report(\n",
    "    y_test, y_pred, labels=[1.0 ,2.0 ,3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0], digits=3))\n",
    "print(\"f1 score:\", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
