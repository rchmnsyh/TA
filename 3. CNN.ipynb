{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiap</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>makan</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kesini</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ngga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pernah</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50531</th>\n",
       "      <td>859</td>\n",
       "      <td>portions</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50532</th>\n",
       "      <td>859</td>\n",
       "      <td>way</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50533</th>\n",
       "      <td>859</td>\n",
       "      <td>too</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50534</th>\n",
       "      <td>859</td>\n",
       "      <td>small</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50535</th>\n",
       "      <td>859</td>\n",
       "      <td>p</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50536 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kalimat #      Word     Tag\n",
       "0              0      tiap       O\n",
       "1              0     makan       O\n",
       "2              0    kesini       O\n",
       "3              0      ngga       O\n",
       "4              0    pernah       O\n",
       "...          ...       ...     ...\n",
       "50531        859  portions  I-FOOD\n",
       "50532        859       way  I-FOOD\n",
       "50533        859       too  I-FOOD\n",
       "50534        859     small  I-FOOD\n",
       "50535        859         p       O\n",
       "\n",
       "[50536 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/dataset_fix.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-FOOD': 1,\n",
       " 'I-FOOD': 2,\n",
       " 'B-MISCELLANEOUS': 3,\n",
       " 'I-MISCELLANEOUS': 4,\n",
       " 'B-SERVICE': 5,\n",
       " 'I-SERVICE': 6,\n",
       " 'B-AMBIENCE': 7,\n",
       " 'I-AMBIENCE': 8,\n",
       " 'B-PRICE': 9,\n",
       " 'I-PRICE': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic={}\n",
    "for i, tag in enumerate(df.Tag.unique()):\n",
    "    dic[tag] = i\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Tag Encoded\"]= df.Tag.apply(lambda x:dic[x])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kalimat = []\n",
    "for i in range(df[\"Kalimat #\"].min(),df[\"Kalimat #\"].max()+1):\n",
    "    list_kata = []\n",
    "    for kata in df[df[\"Kalimat #\"] == i][\"Word\"]:\n",
    "        list_kata.append(str(kata))\n",
    "    list_kalimat.append(list_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kalimat_join = []\n",
    "for kalimat in list_kalimat:\n",
    "    list_kalimat_join.append(\" \".join(kalimat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idwiki_100 = Word2Vec.load(\"Model/idwiki_word2vec_100.model\")\n",
    "list_wv = []\n",
    "for kata in df[\"Word\"]:\n",
    "    wv_kata =np.zeros(100)\n",
    "    if(kata in idwiki_100.wv.vocab):\n",
    "        wv_kata = idwiki_100.wv[kata]\n",
    "    list_wv.append(wv_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>wv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiap</td>\n",
       "      <td>O</td>\n",
       "      <td>[1.7496031522750854, -2.08819317817688, 2.4487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>makan</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.15238453447818756, 0.267755389213562, 1.726...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kesini</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.44860780239105225, 0.24110662937164307, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ngga</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.2567923069000244, 0.2274191975593567, 0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pernah</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.9020400047302246, 2.8760569095611572, 0.432...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kalimat #    Word Tag                                                 wv\n",
       "0          0    tiap   O  [1.7496031522750854, -2.08819317817688, 2.4487...\n",
       "1          0   makan   O  [0.15238453447818756, 0.267755389213562, 1.726...\n",
       "2          0  kesini   O  [0.44860780239105225, 0.24110662937164307, -0....\n",
       "3          0    ngga   O  [0.2567923069000244, 0.2274191975593567, 0.010...\n",
       "4          0  pernah   O  [0.9020400047302246, 2.8760569095611572, 0.432..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"wv\"] = [i.tolist() for i in list_wv]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_B-AMBIENCE', 'x0_B-FOOD', 'x0_B-MISCELLANEOUS', 'x0_B-PRICE',\n",
       "       'x0_B-SERVICE', 'x0_I-AMBIENCE', 'x0_I-FOOD', 'x0_I-MISCELLANEOUS',\n",
       "       'x0_I-PRICE', 'x0_I-SERVICE', 'x0_O'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "toEncode = df[\"Tag\"].values.reshape(-1, 1)\n",
    "enc = enc.fit(toEncode)\n",
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoded = enc.transform(toEncode).toarray()\n",
    "Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>wv</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiap</td>\n",
       "      <td>O</td>\n",
       "      <td>[1.7496031522750854, -2.08819317817688, 2.4487...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>makan</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.15238453447818756, 0.267755389213562, 1.726...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kesini</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.44860780239105225, 0.24110662937164307, -0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ngga</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.2567923069000244, 0.2274191975593567, 0.010...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pernah</td>\n",
       "      <td>O</td>\n",
       "      <td>[0.9020400047302246, 2.8760569095611572, 0.432...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kalimat #    Word Tag                                                 wv  \\\n",
       "0          0    tiap   O  [1.7496031522750854, -2.08819317817688, 2.4487...   \n",
       "1          0   makan   O  [0.15238453447818756, 0.267755389213562, 1.726...   \n",
       "2          0  kesini   O  [0.44860780239105225, 0.24110662937164307, -0....   \n",
       "3          0    ngga   O  [0.2567923069000244, 0.2274191975593567, 0.010...   \n",
       "4          0  pernah   O  [0.9020400047302246, 2.8760569095611572, 0.432...   \n",
       "\n",
       "                                       label_encoded  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label_encoded\"] = [i for i in Encoded]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"wv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"wv\"].values\n",
    "y = df[\"label_encoded\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1301170066)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7550 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = 10000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',\n",
    "                      lower=True, oov_token='UNKNOWN')\n",
    "tokenizer.fit_on_texts(list_kalimat_join)\n",
    "sequences_train = tokenizer.texts_to_sequences(list_kalimat_join) # Ini bingung lagian ga dipake jg\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(x).astype('float32') for x in X_train])\n",
    "y_train = np.array([np.array(x).astype('float32') for x in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train: (40428, 100)\n",
      "Shape of label train: (40428, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X train:', X_train.shape)\n",
    "print('Shape of label train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7551\n"
     ]
    }
   ],
   "source": [
    "word_vectors = idwiki_100.wv\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "vocabulary_size = min(len(word_index)+1,NUM_WORDS)\n",
    "print(\"Vocabulary size:\", vocabulary_size)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "#         embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "        embedding_matrix[i]=np.random.normal(0,0,EMBEDDING_DIM)\n",
    "\n",
    "del(word_vectors)\n",
    "\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "sequence_length = X_train.shape[1]\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(sequence_length, ))\n",
    "\n",
    "# embedding = embedding_layer(inputs)\n",
    "\n",
    "# reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "reshape = Reshape((sequence_length,1))(inputs)\n",
    "\n",
    "conv_0 = Conv1D(num_filters, (filter_sizes[0]),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv1D(num_filters, (filter_sizes[1]),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_2 = Conv1D(num_filters, (filter_sizes[2]),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling1D((sequence_length - filter_sizes[0] + 1), strides=(1))(conv_0)\n",
    "maxpool_1 = MaxPooling1D((sequence_length - filter_sizes[1] + 1), strides=(1))(conv_1)\n",
    "maxpool_2 = MaxPooling1D((sequence_length - filter_sizes[2] + 1), strides=(1))(conv_2)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((11*num_filters,))(flatten)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=11, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 98, 100)      400         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 97, 100)      500         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 96, 100)      600         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 1, 100)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 100)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 100)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 100)       0           max_pooling1d[0][0]              \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 300)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 300)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 11)           3311        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,811\n",
      "Trainable params: 4,811\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='acc', patience=10)]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 1.4612 - acc: 0.6858\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 14s 34ms/step - loss: 1.2193 - acc: 0.6951\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 1.1909 - acc: 0.6951 2s - loss: 1.1 - ETA: 0s - loss: 1.1929 - \n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 1.1828 - acc: 0.6951\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 1.1777 - acc: 0.6951\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 14s 36ms/step - loss: 1.1756 - acc: 0.6951 0s - loss\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 18s 44ms/step - loss: 1.1755 - acc: 0.6951 7s - loss: 1.1758 - a\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 19s 47ms/step - loss: 1.1732 - acc: 0.6951\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 1.1733 - acc: 0.6951\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 17s 43ms/step - loss: 1.1724 - acc: 0.6951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e3c7514c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, epochs=10, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([np.array(x).astype('float32') for x in X_test])\n",
    "# y_test = np.array([np.array(x).astype('float32') for x in y_test])\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00810993, 0.04459351, 0.01231202, 0.00523666, 0.00821869,\n",
       "       0.02503779, 0.12719195, 0.04573906, 0.01367501, 0.02012711,\n",
       "       0.6897583 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
