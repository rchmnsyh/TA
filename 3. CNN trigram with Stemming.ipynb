{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiap</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>makan</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kesini</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ngga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pernah</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50531</th>\n",
       "      <td>859</td>\n",
       "      <td>portions</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50532</th>\n",
       "      <td>859</td>\n",
       "      <td>way</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50533</th>\n",
       "      <td>859</td>\n",
       "      <td>too</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50534</th>\n",
       "      <td>859</td>\n",
       "      <td>small</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50535</th>\n",
       "      <td>859</td>\n",
       "      <td>p</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50536 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kalimat #      Word     Tag\n",
       "0              0      tiap       O\n",
       "1              0     makan       O\n",
       "2              0    kesini       O\n",
       "3              0      ngga       O\n",
       "4              0    pernah       O\n",
       "...          ...       ...     ...\n",
       "50531        859  portions  I-FOOD\n",
       "50532        859       way  I-FOOD\n",
       "50533        859       too  I-FOOD\n",
       "50534        859     small  I-FOOD\n",
       "50535        859         p       O\n",
       "\n",
       "[50536 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/dataset_fix.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-FOOD', 'I-FOOD', 'B-MISCELLANEOUS', 'I-MISCELLANEOUS',\n",
       "       'B-SERVICE', 'I-SERVICE', 'B-AMBIENCE', 'I-AMBIENCE', 'B-PRICE',\n",
       "       'I-PRICE'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tag\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>35068</td>\n",
       "      <td>35065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-FOOD</th>\n",
       "      <td>1973</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-FOOD</th>\n",
       "      <td>6799</td>\n",
       "      <td>6799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISCELLANEOUS</th>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISCELLANEOUS</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-SERVICE</th>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-SERVICE</th>\n",
       "      <td>1306</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-AMBIENCE</th>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-AMBIENCE</th>\n",
       "      <td>1247</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PRICE</th>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PRICE</th>\n",
       "      <td>633</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Kalimat #   Word\n",
       "Tag                              \n",
       "O                    35068  35065\n",
       "B-FOOD                1973   1973\n",
       "I-FOOD                6799   6799\n",
       "B-MISCELLANEOUS        551    551\n",
       "I-MISCELLANEOUS       1992   1992\n",
       "B-SERVICE              358    358\n",
       "I-SERVICE             1306   1306\n",
       "B-AMBIENCE             392    392\n",
       "I-AMBIENCE            1247   1247\n",
       "B-PRICE                217    217\n",
       "I-PRICE                633    633"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Tag\", sort=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-FOOD': 1,\n",
       " 'I-FOOD': 2,\n",
       " 'B-MISCELLANEOUS': 3,\n",
       " 'I-MISCELLANEOUS': 4,\n",
       " 'B-SERVICE': 5,\n",
       " 'I-SERVICE': 6,\n",
       " 'B-AMBIENCE': 7,\n",
       " 'I-AMBIENCE': 8,\n",
       " 'B-PRICE': 9,\n",
       " 'I-PRICE': 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic={}\n",
    "for i, tag in enumerate(df.Tag.unique()):\n",
    "    dic[tag] = i\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "50531    2\n",
       "50532    2\n",
       "50533    2\n",
       "50534    2\n",
       "50535    0\n",
       "Name: Tag, Length: 50536, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"Tag\"].apply(lambda x:dic[x])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "list_kalimat = []\n",
    "\n",
    "for i in range(df[\"Kalimat #\"].min(),df[\"Kalimat #\"].max()+1):\n",
    "    list_kata = [\"<S>\"]\n",
    "    for kata in df[df[\"Kalimat #\"] == i][\"Word\"]:\n",
    "        list_kata.append(stemmer.stem(str(kata)))\n",
    "    list_kata.append(\"</S>\")\n",
    "    list_kalimat.append(list_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enakkkkkk'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"enakkkkkk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kalimat_join = []\n",
    "for kalimat in list_kalimat:\n",
    "    list_kalimat_join.append(\" \".join(kalimat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<S>', 'tiap', 'makan', 'kesini', 'ngga', 'pernah', 'cuma', '1', 'atau', '2', 'porsi', 'pasti', 'nambah', 'terus', 'karena', 'emang', 'pas', 'banget', 'rasa', 'di', 'lidah', 'black', 'peppernya', 'yang', 'paling', 'enak', 'sini', 'emang', 'selalu', 'waiting', 'list', 'cuma', 'sei', 'sapi', 'lamalera', 'absolutely', 'worth', 'to', 'wait', 'recommended', '</S>']\n"
     ]
    }
   ],
   "source": [
    "print(list_kalimat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> tiap makan kesini ngga pernah cuma 1 atau 2 porsi pasti nambah terus karena emang pas banget rasa di lidah black peppernya yang paling enak sini emang selalu waiting list cuma sei sapi lamalera absolutely worth to wait recommended </S>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_kalimat_join[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = []\n",
    "for kalimat in (list_kalimat):\n",
    "    for i in range(len(kalimat)):\n",
    "        if i > 0 and i < len(kalimat)-1:\n",
    "            trigram.append([kalimat[i-1], kalimat[i], kalimat[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6527 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS=10000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='!\"#$%&()*+,-.:;=?@[\\\\]^_`{|}~\\t\\n\\'',\n",
    "                      lower=True)\n",
    "tokenizer.fit_on_texts(trigram)\n",
    "sequences_train = tokenizer.texts_to_sequences(trigram)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_0', 'x0_1', 'x0_2', 'x0_3', 'x0_4', 'x0_5', 'x0_6', 'x0_7',\n",
       "       'x0_8', 'x0_9', 'x0_10'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "toEncode = labels.values.reshape(-1, 1)\n",
    "enc = enc.fit(toEncode)\n",
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoded = enc.transform(toEncode).toarray()\n",
    "Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigram</th>\n",
       "      <th>Label</th>\n",
       "      <th>Trigram Encoded</th>\n",
       "      <th>Label Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[&lt;S&gt;, tiap, makan]</td>\n",
       "      <td>O</td>\n",
       "      <td>[17, 251, 7]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tiap, makan, kesini]</td>\n",
       "      <td>O</td>\n",
       "      <td>[251, 7, 57]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[makan, kesini, ngga]</td>\n",
       "      <td>O</td>\n",
       "      <td>[7, 57, 1026]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kesini, ngga, pernah]</td>\n",
       "      <td>O</td>\n",
       "      <td>[57, 1026, 181]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ngga, pernah, cuma]</td>\n",
       "      <td>O</td>\n",
       "      <td>[1026, 181, 100]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50531</th>\n",
       "      <td>[the, portions, way]</td>\n",
       "      <td>I-FOOD</td>\n",
       "      <td>[4, 1610, 710]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50532</th>\n",
       "      <td>[portions, way, too]</td>\n",
       "      <td>I-FOOD</td>\n",
       "      <td>[1610, 710, 153]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50533</th>\n",
       "      <td>[way, too, small]</td>\n",
       "      <td>I-FOOD</td>\n",
       "      <td>[710, 153, 426]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50534</th>\n",
       "      <td>[too, small, p]</td>\n",
       "      <td>I-FOOD</td>\n",
       "      <td>[153, 426, 3125]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50535</th>\n",
       "      <td>[small, p, &lt;/S&gt;]</td>\n",
       "      <td>O</td>\n",
       "      <td>[426, 3125, 18]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50536 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Trigram   Label   Trigram Encoded  \\\n",
       "0          [<S>, tiap, makan]       O      [17, 251, 7]   \n",
       "1       [tiap, makan, kesini]       O      [251, 7, 57]   \n",
       "2       [makan, kesini, ngga]       O     [7, 57, 1026]   \n",
       "3      [kesini, ngga, pernah]       O   [57, 1026, 181]   \n",
       "4        [ngga, pernah, cuma]       O  [1026, 181, 100]   \n",
       "...                       ...     ...               ...   \n",
       "50531    [the, portions, way]  I-FOOD    [4, 1610, 710]   \n",
       "50532    [portions, way, too]  I-FOOD  [1610, 710, 153]   \n",
       "50533       [way, too, small]  I-FOOD   [710, 153, 426]   \n",
       "50534         [too, small, p]  I-FOOD  [153, 426, 3125]   \n",
       "50535        [small, p, </S>]       O   [426, 3125, 18]   \n",
       "\n",
       "                                           Label Encoded  \n",
       "0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "50531  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "50532  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "50533  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "50534  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "50535  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[50536 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trigram = pd.DataFrame(columns=[\"Trigram\", \"Label\", \"Trigram Encoded\", \"Label Encoded\"], data=zip(trigram, df[\"Tag\"].values, sequences_train, Encoded))\n",
    "df_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_trigram[\"Trigram Encoded\"].values, df_trigram[\"Label Encoded\"].values, test_size=0.2, random_state=1301170066, shuffle=True, stratify=labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(x).astype('float32') for x in X_train])\n",
    "y_train = np.array([np.array(x).astype('float32') for x in y_train])\n",
    "\n",
    "X_test = np.array([np.array(x).astype('float32') for x in X_test])\n",
    "y_test = np.array([np.array(x).astype('float32') for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train: (40428, 3)\n",
      "Shape of label train: (40428, 11)\n",
      "Shape of X test: (10108, 3)\n",
      "Shape of label test: (10108, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X train:', X_train.shape)\n",
    "print('Shape of label train:', y_train.shape)\n",
    "\n",
    "print('Shape of X test:', X_test.shape)\n",
    "print('Shape of label test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "idwiki_300 = Word2Vec.load(\"Model/idwiki_word2vec_300.model\")\n",
    "word_vectors = idwiki_300.wv\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "vocabulary_size = min(len(word_index)+1,NUM_WORDS)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "\n",
    "del(word_vectors)\n",
    "\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40428, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout, concatenate, LSTM\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "sequence_length = X_train.shape[1]\n",
    "filter_sizes = [1,2,3]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_2 = Conv2D(num_filters, (filter_sizes[2], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=(1,1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(1,1))(conv_1)\n",
    "maxpool_2 = MaxPooling2D((sequence_length - filter_sizes[2] + 1, 1), strides=(1,1))(conv_2)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=11, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 3, 300)       1958400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 3, 300, 1)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 3, 1, 100)    30100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 2, 1, 100)    60100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 100)    90100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 100)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 1, 100)    0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 300)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 300)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 11)           3311        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,142,011\n",
      "Trainable params: 2,142,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "405/405 [==============================] - 17s 43ms/step - loss: 1.1914 - acc: 0.7141 - val_loss: 1.0359 - val_acc: 0.7365\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 16s 40ms/step - loss: 1.0121 - acc: 0.7347 - val_loss: 0.9737 - val_acc: 0.7410\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 17s 42ms/step - loss: 0.9474 - acc: 0.7505 - val_loss: 0.9468 - val_acc: 0.7466\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 19s 46ms/step - loss: 0.8999 - acc: 0.7624 - val_loss: 0.9095 - val_acc: 0.7569\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 18s 44ms/step - loss: 0.8717 - acc: 0.7710 - val_loss: 0.9061 - val_acc: 0.7621\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 18s 45ms/step - loss: 0.8476 - acc: 0.7766 - val_loss: 0.8925 - val_acc: 0.7604\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 18s 45ms/step - loss: 0.8280 - acc: 0.7827 - val_loss: 0.8788 - val_acc: 0.7680\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 25s 62ms/step - loss: 0.8127 - acc: 0.7861 - val_loss: 0.8702 - val_acc: 0.7723\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 27s 68ms/step - loss: 0.7995 - acc: 0.7897 - val_loss: 0.8640 - val_acc: 0.7693\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 24s 60ms/step - loss: 0.7852 - acc: 0.7924 - val_loss: 0.8633 - val_acc: 0.7752\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 23s 56ms/step - loss: 0.7767 - acc: 0.7958 - val_loss: 0.8556 - val_acc: 0.7723\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 25s 61ms/step - loss: 0.7629 - acc: 0.8002 - val_loss: 0.8498 - val_acc: 0.7752\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 24s 58ms/step - loss: 0.7566 - acc: 0.8017 - val_loss: 0.8494 - val_acc: 0.7745\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 19s 48ms/step - loss: 0.7463 - acc: 0.8053 - val_loss: 0.8466 - val_acc: 0.7796\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 22s 54ms/step - loss: 0.7371 - acc: 0.8070 - val_loss: 0.8371 - val_acc: 0.7792\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 23s 56ms/step - loss: 0.7290 - acc: 0.8086 - val_loss: 0.8391 - val_acc: 0.7766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba1ffc0d48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=100, \n",
    "          epochs=100, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_argmax = [np.argmax(i) for i in y_test]\n",
    "y_pred_argmax = [np.argmax(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.557     0.334     0.418       395\n",
      "           2      0.627     0.520     0.569      1360\n",
      "           3      0.600     0.027     0.052       110\n",
      "           4      0.545     0.195     0.288       399\n",
      "           5      0.660     0.431     0.521        72\n",
      "           6      0.695     0.410     0.516       261\n",
      "           7      0.739     0.218     0.337        78\n",
      "           8      0.593     0.434     0.501       249\n",
      "           9      0.793     0.535     0.639        43\n",
      "          10      0.746     0.346     0.473       127\n",
      "\n",
      "   micro avg      0.623     0.404     0.490      3094\n",
      "   macro avg      0.656     0.345     0.431      3094\n",
      "weighted avg      0.621     0.404     0.475      3094\n",
      "\n",
      "f1 score: 0.7766125840918084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "\n",
    "print(classification_report(\n",
    "    y_test_argmax, y_pred_argmax, labels=[1,2,3,4,5,6,7,8,9,10], digits=3))\n",
    "print(\"f1 score:\", f1_score(y_test_argmax, y_pred_argmax, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
