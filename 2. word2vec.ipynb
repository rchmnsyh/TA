{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import time\n",
    "import multiprocessing\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiap</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>makan</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kesini</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ngga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pernah</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50531</th>\n",
       "      <td>859</td>\n",
       "      <td>portions</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50532</th>\n",
       "      <td>859</td>\n",
       "      <td>way</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50533</th>\n",
       "      <td>859</td>\n",
       "      <td>too</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50534</th>\n",
       "      <td>859</td>\n",
       "      <td>small</td>\n",
       "      <td>I-FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50535</th>\n",
       "      <td>859</td>\n",
       "      <td>p</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50536 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kalimat #      Word     Tag\n",
       "0              0      tiap       O\n",
       "1              0     makan       O\n",
       "2              0    kesini       O\n",
       "3              0      ngga       O\n",
       "4              0    pernah       O\n",
       "...          ...       ...     ...\n",
       "50531        859  portions  I-FOOD\n",
       "50532        859       way  I-FOOD\n",
       "50533        859       too  I-FOOD\n",
       "50534        859     small  I-FOOD\n",
       "50535        859         p       O\n",
       "\n",
       "[50536 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/dataset_fix.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7552"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"Word\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in range(1,df[\"Kalimat #\"].max()+1):\n",
    "    # print(i)\n",
    "    kalimat = []\n",
    "    for kata in df[df[\"Kalimat #\"] == i].Word:\n",
    "        kata = str(kata)\n",
    "        kalimat.append(kata)\n",
    "    # print(kalimat)\n",
    "    # kalimat = \" \".join(kalimat)\n",
    "    text.append(kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model...\n",
      "Finished. Elapsed time: 0:00:00.688096\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Training Word2Vec Model...')\n",
    "id_w2v = word2vec.Word2Vec(text, size=128, window=5, workers=multiprocessing.cpu_count()-1)\n",
    "id_w2v.save('Model/w2v.model')\n",
    "finish_time = time.time()\n",
    "print('Finished. Elapsed time: {}'.format(timedelta(seconds=finish_time-start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x2949f8d39c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector = id_w2v.wv\n",
    "word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tidak', 0.9999445676803589),\n",
       " ('rasa', 0.9999441504478455),\n",
       " ('lumayan', 0.9999414086341858),\n",
       " ('cukup', 0.9999408721923828),\n",
       " ('buat', 0.9999399185180664),\n",
       " ('aku', 0.9999390840530396),\n",
       " ('pas', 0.9999379515647888),\n",
       " ('dengan', 0.9999364018440247),\n",
       " ('harga', 0.9999359250068665),\n",
       " ('rasanya', 0.9999352693557739)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = \"makanan\"\n",
    "word_vector.most_similar(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idwiki_100 = word2vec.Word2Vec.load(\"Model/idwiki_word2vec_100.model\")\n",
    "idwiki_200 = word2vec.Word2Vec.load(\"Model/idwiki_word2vec_200.model\")\n",
    "idwiki_300 = word2vec.Word2Vec.load(\"Model/idwiki_word2vec_300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = makanan\n",
      "\n",
      "idwiki_100\n",
      "[('minuman', 0.7553930878639221), ('sayuran', 0.7550625801086426), ('hidangan', 0.7483913898468018), ('daging', 0.7375621795654297), ('masakan', 0.7172369360923767), ('penganan', 0.6943979263305664), ('dagingnya', 0.6922298669815063), ('makan', 0.6910635232925415), ('lauk', 0.6897751092910767), ('sayur', 0.689528226852417)]\n",
      "\n",
      "idwiki_200\n",
      "[('hidangan', 0.7060810327529907), ('minuman', 0.6646443605422974), ('masakan', 0.6525181531906128), ('daging', 0.6479215621948242), ('sayuran', 0.643390417098999), ('pakan', 0.6276005506515503), ('jajanan', 0.6249856352806091), ('nutrisi', 0.6226201057434082), ('sajian', 0.6139245629310608), ('makan', 0.6124954223632812)]\n",
      "\n",
      "idwiki_300\n",
      "[('hidangan', 0.6628608703613281), ('minuman', 0.6179170608520508), ('sayuran', 0.6050371527671814), ('masakan', 0.6007183790206909), ('daging', 0.5991817116737366), ('penganan', 0.5940256118774414), ('lauk', 0.5920421481132507), ('nutrisi', 0.5871155261993408), ('dagingnya', 0.5867141485214233), ('sayur', 0.5827234387397766)]\n"
     ]
    }
   ],
   "source": [
    "print(\"word =\", w)\n",
    "print()\n",
    "print(\"idwiki_100\")\n",
    "print(idwiki_100.wv.most_similar(w))\n",
    "print()\n",
    "print(\"idwiki_200\")\n",
    "print(idwiki_200.wv.most_similar(w))\n",
    "print()\n",
    "print(\"idwiki_300\")\n",
    "print(idwiki_300.wv.most_similar(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = instagramable\n",
      "\n",
      "idwiki_100\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'instagramable' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1c73b73cd65a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"idwiki_100\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midwiki_100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"idwiki_200\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'instagramable' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "w = \"instagramable\"\n",
    "print(\"word =\", w)\n",
    "print()\n",
    "print(\"idwiki_100\")\n",
    "print(idwiki_100.wv.most_similar(w))\n",
    "print()\n",
    "print(\"idwiki_200\")\n",
    "print(idwiki_200.wv.most_similar(w))\n",
    "print()\n",
    "print(\"idwiki_300\")\n",
    "print(idwiki_300.wv.most_similar(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idwiki_update = word2vec.Word2Vec.load(\"Model/idwiki_word2vec_100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tidur', 0.7243797779083252),\n",
       " ('minum', 0.7189054489135742),\n",
       " ('menyantap', 0.718381404876709),\n",
       " ('memasak', 0.713307797908783),\n",
       " ('makanan', 0.6910635232925415),\n",
       " ('sarapan', 0.6861647963523865),\n",
       " ('makannya', 0.6823428869247437),\n",
       " ('bersantai', 0.6686819791793823),\n",
       " ('sajikan', 0.667438268661499),\n",
       " ('berpesta', 0.6597975492477417)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = \"makan\"\n",
    "idwiki_100.wv.most_similar(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Count before Update = 348902\n",
      "Vocab before Update = 331792\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus Count before Update =\", idwiki_update.corpus_count)\n",
    "print(\"Vocab before Update =\", len(idwiki_update.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204430, 252485)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idwiki_update.build_vocab(text, update=True)\n",
    "idwiki_update.train(text, total_examples=idwiki_update.corpus_count, epochs=idwiki_update.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Count after Update Vocab = 859\n",
      "Vocab after Update = 331914\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus Count after Update =\", idwiki_update.corpus_count)\n",
    "print(\"Vocab after Update =\", len(idwiki_update.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tidur', 0.7297677993774414),\n",
       " ('minum', 0.7099161744117737),\n",
       " ('menyantap', 0.702729344367981),\n",
       " ('memasak', 0.7021759748458862),\n",
       " ('makannya', 0.701756477355957),\n",
       " ('makanan', 0.689060628414154),\n",
       " ('sarapan', 0.6799747347831726),\n",
       " ('sajikan', 0.6770439743995667),\n",
       " ('bersantai', 0.6752710938453674),\n",
       " ('berpesta', 0.657168984413147)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idwiki_update.wv.most_similar(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idwiki_update.save('Model/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
